{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Comparing Model Performance with Radiologists\n",
    "\n",
    "**Author:** [Your Name]\n",
    "\n",
    "**Date:** [Current Date]\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook is part of the VSF-Med (Vulnerability Scoring Framework for Medical Vision-Language Models) research project. It compares the performance of vision-language models against radiologists in interpreting chest X-rays, with a focus on how adversarial inputs affect this comparison.\n",
    "\n",
    "### Purpose\n",
    "- Compare model performance with radiologist ground truth under standard conditions\n",
    "- Analyze how adversarial inputs affect model-radiologist agreement\n",
    "- Identify clinical implications of model vulnerabilities\n",
    "- Assess the potential impact on patient care when using vulnerable models\n",
    "- Provide recommendations for safe deployment of vision-language models in clinical settings\n",
    "\n",
    "### Workflow\n",
    "1. Load model responses and radiologist interpretations from the database\n",
    "2. Calculate agreement metrics between models and radiologists\n",
    "3. Compare agreement under standard vs. adversarial conditions\n",
    "4. Analyze clinical implications of disagreements\n",
    "5. Generate visualizations and insights for publication\n",
    "\n",
    "### Clinical Relevance\n",
    "This analysis addresses the critical question: \"How do vulnerabilities in vision-language models impact their agreement with radiologists?\" This has direct implications for the safe deployment of AI in clinical settings and patient care."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "### 1.1 Install Required Libraries\n",
    "\n",
    "First, we'll install all necessary libraries for data analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "!pip install pandas numpy matplotlib seaborn sqlalchemy psycopg2-binary python-dotenv pyyaml scikit-learn nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Add the src directory to the path for importing custom modules\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set up plotting defaults\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "\n",
    "# Check platform for environment-specific settings\n",
    "import platform\n",
    "operating_system = platform.system()\n",
    "print(f\"Operating System: {operating_system}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Configuration Setup\n",
    "\n",
    "Load configuration from YAML file and set up environment-specific settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load configuration\n",
    "config_path = os.path.join(parent_dir, 'src', 'config', 'default_config.yaml')\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Configure paths based on operating system\n",
    "if operating_system == 'Darwin':  # macOS\n",
    "    output_dir = os.path.expanduser('~/data/vsf-med/output')\n",
    "elif operating_system == 'Linux':\n",
    "    output_dir = '/data/vsf-med/output'\n",
    "else:  # Windows or other\n",
    "    output_dir = config['paths']['output_dir'].replace('${HOME}', os.path.expanduser('~'))\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "figures_dir = os.path.join(output_dir, 'figures')\n",
    "os.makedirs(figures_dir, exist_ok=True)\n",
    "\n",
    "# Set up database connection\n",
    "db_config = config['database']\n",
    "db_password = os.environ.get('DB_PASSWORD', '')\n",
    "CONNECTION_STRING = f\"postgresql://{db_config['user']}:{db_password}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(CONNECTION_STRING)\n",
    "\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Figures directory: {figures_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Collection\n",
    "\n",
    "Fetch model responses and radiologist interpretations from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def fetch_model_responses_with_ground_truth():\n",
    "    \"\"\"\n",
    "    Fetch model responses along with radiologist ground truth from the database.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing model responses and ground truth\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT r.id, r.uid, r.question_id, r.question, r.question_category, r.model_name, \n",
    "           r.model_answer, r.image_link, r.actual_answer, q.answer as radiologist_answer\n",
    "    FROM mimicxp.model_responses_r2 r\n",
    "    LEFT JOIN mimicxp.mimic_all_qns q ON r.question_id = q.question_id::text\n",
    "    WHERE q.answer IS NOT NULL\n",
    "    ORDER BY r.created_at DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        df = pd.read_sql(query, conn)\n",
    "    \n",
    "    print(f\"Fetched {len(df)} model responses with ground truth\")\n",
    "    return df\n",
    "\n",
    "def fetch_evaluations_with_ground_truth():\n",
    "    \"\"\"\n",
    "    Fetch model evaluations with radiologist ground truth from the database.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing evaluations and ground truth\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT e.*, r.model_name, r.question_category, r.question, r.model_answer, \n",
    "           r.actual_answer, q.answer as radiologist_answer\n",
    "    FROM mimicxp.evaluations e\n",
    "    JOIN mimicxp.model_responses_r2 r ON e.model_response_id = r.id\n",
    "    LEFT JOIN mimicxp.mimic_all_qns q ON r.question_id = q.question_id::text\n",
    "    WHERE q.answer IS NOT NULL\n",
    "    ORDER BY e.created_at DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        df = pd.read_sql(query, conn)\n",
    "    \n",
    "    print(f\"Fetched {len(df)} evaluations with ground truth\")\n",
    "    return df\n",
    "\n",
    "# Fetch data\n",
    "responses_with_gt = fetch_model_responses_with_ground_truth()\n",
    "evaluations_with_gt = fetch_evaluations_with_ground_truth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare data for analysis\n",
    "def preprocess_data(responses_df, evaluations_df):\n",
    "    \"\"\"\n",
    "    Preprocess and prepare data for model-radiologist comparison.\n",
    "    \n",
    "    Args:\n",
    "        responses_df (pd.DataFrame): DataFrame with model responses\n",
    "        evaluations_df (pd.DataFrame): DataFrame with evaluations\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with processed DataFrames\n",
    "    \"\"\"\n",
    "    # Check if we have data\n",
    "    if responses_df.empty or evaluations_df.empty:\n",
    "        print(\"Warning: Empty data. Cannot proceed with analysis.\")\n",
    "        return {}\n",
    "        \n",
    "    # Add category type (text attack, visual perturbation, original)\n",
    "    def categorize_question(category):\n",
    "        if category == 'original':\n",
    "            return 'baseline'\n",
    "        elif category.startswith('visual_perturb'):\n",
    "            return 'visual_perturbation'\n",
    "        elif category.startswith('text_attack'):\n",
    "            return 'text_attack'\n",
    "        else:\n",
    "            return 'other'\n",
    "    \n",
    "    # Add category type to responses\n",
    "    responses_df['category_type'] = responses_df['question_category'].apply(categorize_question)\n",
    "    \n",
    "    # Add category type to evaluations\n",
    "    evaluations_df['category_type'] = evaluations_df['question_category'].apply(categorize_question)\n",
    "    \n",
    "    # Add model info to evaluations\n",
    "    evaluations_df['model_name'] = evaluations_df['model_name']\n",
    "    \n",
    "    # Merge evaluations with responses\n",
    "    merged_df = pd.merge(\n",
    "        evaluations_df,\n",
    "        responses_df[['id', 'radiologist_answer']],\n",
    "        left_on='model_response_id',\n",
    "        right_on='id',\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'responses': responses_df,\n",
    "        'evaluations': evaluations_df,\n",
    "        'merged': merged_df\n",
    "    }\n",
    "\n",
    "# Process data\n",
    "data = preprocess_data(responses_with_gt, evaluations_with_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Similarity Metrics\n",
    "\n",
    "Calculate text similarity between model responses and radiologist interpretations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def calculate_text_similarity(text1, text2):\n",
    "    \"\"\"\n",
    "    Calculate text similarity metrics between two text strings.\n",
    "    \n",
    "    Args:\n",
    "        text1 (str): First text string\n",
    "        text2 (str): Second text string\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary of similarity metrics\n",
    "    \"\"\"\n",
    "    # Handle null values\n",
    "    if not isinstance(text1, str) or not isinstance(text2, str):\n",
    "        return {\n",
    "            'bleu': 0.0,\n",
    "            'meteor': 0.0,\n",
    "            'word_overlap': 0.0\n",
    "        }\n",
    "    \n",
    "    # Tokenize texts\n",
    "    tokens1 = word_tokenize(text1.lower())\n",
    "    tokens2 = word_tokenize(text2.lower())\n",
    "    \n",
    "    # Calculate BLEU score\n",
    "    try:\n",
    "        bleu = sentence_bleu([tokens1], tokens2, weights=(1, 0, 0, 0))\n",
    "    except Exception:\n",
    "        bleu = 0.0\n",
    "    \n",
    "    # Calculate METEOR score\n",
    "    try:\n",
    "        meteor = meteor_score([tokens1], tokens2)\n",
    "    except Exception:\n",
    "        meteor = 0.0\n",
    "    \n",
    "    # Calculate word overlap (Jaccard similarity)\n",
    "    set1 = set(tokens1)\n",
    "    set2 = set(tokens2)\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    word_overlap = intersection / union if union > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'bleu': bleu,\n",
    "        'meteor': meteor,\n",
    "        'word_overlap': word_overlap\n",
    "    }\n",
    "\n",
    "def extract_diagnoses(text):\n",
    "    \"\"\"\n",
    "    Extract medical diagnoses from text using pattern matching.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to extract diagnoses from\n",
    "        \n",
    "    Returns:\n",
    "        list: List of extracted diagnoses\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    # Common chest X-ray findings/diagnoses\n",
    "    diagnoses = [\n",
    "        \"pneumonia\", \"effusion\", \"edema\", \"atelectasis\", \"consolidation\",\n",
    "        \"nodule\", \"mass\", \"pneumothorax\", \"pleural effusion\", \"cardiomegaly\",\n",
    "        \"emphysema\", \"fibrosis\", \"infiltrate\", \"opacity\", \"pleural thickening\",\n",
    "        \"pulmonary edema\", \"fracture\", \"lung cancer\", \"tuberculosis\", \"covid\",\n",
    "        \"copd\", \"bronchitis\", \"bronchiectasis\", \"collapse\", \"hiatal hernia\"\n",
    "    ]\n",
    "    \n",
    "    # Create regex pattern for diagnoses\n",
    "    pattern = r'\\b(' + '|'.join(diagnoses) + r')\\b'\n",
    "    \n",
    "    # Find all matches\n",
    "    matches = re.findall(pattern, text.lower())\n",
    "    \n",
    "    # Return unique diagnoses\n",
    "    return list(set(matches))\n",
    "\n",
    "def calculate_diagnosis_agreement(text1, text2):\n",
    "    \"\"\"\n",
    "    Calculate agreement between diagnoses in two texts.\n",
    "    \n",
    "    Args:\n",
    "        text1 (str): First text (typically radiologist interpretation)\n",
    "        text2 (str): Second text (typically model response)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary of agreement metrics\n",
    "    \"\"\"\n",
    "    # Extract diagnoses\n",
    "    diagnoses1 = extract_diagnoses(text1)\n",
    "    diagnoses2 = extract_diagnoses(text2)\n",
    "    \n",
    "    # Handle empty diagnoses\n",
    "    if not diagnoses1 or not diagnoses2:\n",
    "        return {\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'f1': 0.0,\n",
    "            'diagnoses1': diagnoses1,\n",
    "            'diagnoses2': diagnoses2\n",
    "        }\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score\n",
    "    tp = len(set(diagnoses1).intersection(set(diagnoses2)))\n",
    "    fp = len(set(diagnoses2) - set(diagnoses1))\n",
    "    fn = len(set(diagnoses1) - set(diagnoses2))\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'diagnoses1': diagnoses1,\n",
    "        'diagnoses2': diagnoses2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate similarity metrics\n",
    "if data and not data['responses'].empty:\n",
    "    # Create copy of responses dataframe\n",
    "    responses = data['responses'].copy()\n",
    "    \n",
    "    # Initialize similarity metrics columns\n",
    "    responses['bleu'] = 0.0\n",
    "    responses['meteor'] = 0.0\n",
    "    responses['word_overlap'] = 0.0\n",
    "    responses['diagnosis_precision'] = 0.0\n",
    "    responses['diagnosis_recall'] = 0.0\n",
    "    responses['diagnosis_f1'] = 0.0\n",
    "    responses['radiologist_diagnoses'] = None\n",
    "    responses['model_diagnoses'] = None\n",
    "    \n",
    "    # Calculate similarity for each row\n",
    "    for idx, row in tqdm(responses.iterrows(), total=len(responses)):\n",
    "        # Calculate text similarity\n",
    "        similarity = calculate_text_similarity(row['radiologist_answer'], row['model_answer'])\n",
    "        responses.at[idx, 'bleu'] = similarity['bleu']\n",
    "        responses.at[idx, 'meteor'] = similarity['meteor']\n",
    "        responses.at[idx, 'word_overlap'] = similarity['word_overlap']\n",
    "        \n",
    "        # Calculate diagnosis agreement\n",
    "        agreement = calculate_diagnosis_agreement(row['radiologist_answer'], row['model_answer'])\n",
    "        responses.at[idx, 'diagnosis_precision'] = agreement['precision']\n",
    "        responses.at[idx, 'diagnosis_recall'] = agreement['recall']\n",
    "        responses.at[idx, 'diagnosis_f1'] = agreement['f1']\n",
    "        responses.at[idx, 'radiologist_diagnoses'] = str(agreement['diagnoses1'])\n",
    "        responses.at[idx, 'model_diagnoses'] = str(agreement['diagnoses2'])\n",
    "    \n",
    "    # Add to data dictionary\n",
    "    data['responses_with_metrics'] = responses\n",
    "    \n",
    "    # Display summary statistics\n",
    "    metrics = ['bleu', 'meteor', 'word_overlap', 'diagnosis_precision', 'diagnosis_recall', 'diagnosis_f1']\n",
    "    summary = responses[metrics].describe()\n",
    "    print(\"\\nSimilarity metrics summary:\")\n",
    "    display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model-Radiologist Agreement Analysis\n",
    "\n",
    "Analyze agreement between model responses and radiologist interpretations across different conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare model-radiologist agreement across category types\n",
    "if data and 'responses_with_metrics' in data:\n",
    "    responses = data['responses_with_metrics']\n",
    "    \n",
    "    # Group by model and category type\n",
    "    grouped = responses.groupby(['model_name', 'category_type'])\n",
    "    \n",
    "    # Calculate average similarity metrics by group\n",
    "    metrics = ['bleu', 'meteor', 'word_overlap', 'diagnosis_precision', 'diagnosis_recall', 'diagnosis_f1']\n",
    "    agreement_by_category = grouped[metrics].mean().reset_index()\n",
    "    \n",
    "    # Display agreement by category\n",
    "    print(\"\\nAverage model-radiologist agreement by category type:\")\n",
    "    display(agreement_by_category)\n",
    "    \n",
    "    # Create grouped bar chart for agreement metrics\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Plot F1 scores by model and category\n",
    "    sns.barplot(data=agreement_by_category, x='model_name', y='diagnosis_f1', hue='category_type')\n",
    "    plt.title('Model-Radiologist Diagnosis Agreement (F1) by Category', fontsize=15)\n",
    "    plt.xlabel('Model', fontsize=12)\n",
    "    plt.ylabel('F1 Score (Diagnosis Agreement)', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(title='Category Type')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(os.path.join(figures_dir, 'diagnosis_agreement_by_category.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate agreement change from baseline to adversarial\n",
    "if data and 'responses_with_metrics' in data:\n",
    "    responses = data['responses_with_metrics']\n",
    "    \n",
    "    # Filter to include only models with both baseline and adversarial examples\n",
    "    valid_models = []\n",
    "    for model in responses['model_name'].unique():\n",
    "        categories = responses[responses['model_name'] == model]['category_type'].unique()\n",
    "        if 'baseline' in categories and ('text_attack' in categories or 'visual_perturbation' in categories):\n",
    "            valid_models.append(model)\n",
    "    \n",
    "    # Filter responses to valid models\n",
    "    valid_responses = responses[responses['model_name'].isin(valid_models)]\n",
    "    \n",
    "    # Group by model and category type\n",
    "    grouped = valid_responses.groupby(['model_name', 'category_type'])\n",
    "    \n",
    "    # Calculate average F1 score by group\n",
    "    avg_f1 = grouped['diagnosis_f1'].mean().reset_index()\n",
    "    \n",
    "    # Pivot data for calculation\n",
    "    f1_pivot = avg_f1.pivot(index='model_name', columns='category_type', values='diagnosis_f1')\n",
    "    \n",
    "    # Calculate percentage change from baseline\n",
    "    changes = pd.DataFrame(index=f1_pivot.index)\n",
    "    \n",
    "    if 'baseline' in f1_pivot.columns:\n",
    "        if 'text_attack' in f1_pivot.columns:\n",
    "            changes['text_attack_pct_change'] = (f1_pivot['text_attack'] - f1_pivot['baseline']) / f1_pivot['baseline'] * 100\n",
    "        \n",
    "        if 'visual_perturbation' in f1_pivot.columns:\n",
    "            changes['visual_perturbation_pct_change'] = (f1_pivot['visual_perturbation'] - f1_pivot['baseline']) / f1_pivot['baseline'] * 100\n",
    "    \n",
    "    # Display percentage changes\n",
    "    print(\"\\nPercentage change in model-radiologist agreement (F1) from baseline:\")\n",
    "    display(changes)\n",
    "    \n",
    "    # Create bar chart of percentage changes\n",
    "    if not changes.empty:\n",
    "        # Reshape data for plotting\n",
    "        changes_long = changes.reset_index().melt(\n",
    "            id_vars=['model_name'],\n",
    "            var_name='category_type',\n",
    "            value_name='percent_change'\n",
    "        )\n",
    "        \n",
    "        # Clean up category names\n",
    "        changes_long['category_type'] = changes_long['category_type'].str.replace('_pct_change', '')\n",
    "        \n",
    "        # Create bar chart\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(data=changes_long, x='model_name', y='percent_change', hue='category_type')\n",
    "        plt.title('Percentage Change in Model-Radiologist Agreement from Baseline', fontsize=15)\n",
    "        plt.xlabel('Model', fontsize=12)\n",
    "        plt.ylabel('Percentage Change in F1 Score (%)', fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "        plt.legend(title='Category Type')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        plt.savefig(os.path.join(figures_dir, 'agreement_percentage_change.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Vulnerability Impact on Clinical Utility\n",
    "\n",
    "Analyze how model vulnerabilities affect potential clinical utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze relationship between vulnerability scores and model-radiologist agreement\n",
    "if data and 'responses_with_metrics' in data and not data['merged'].empty:\n",
    "    # Get merged data with both vulnerability scores and agreement metrics\n",
    "    merged = data['merged'].copy()\n",
    "    responses_with_metrics = data['responses_with_metrics']\n",
    "    \n",
    "    # Add agreement metrics to merged data\n",
    "    metrics_map = responses_with_metrics[['id', 'diagnosis_f1', 'bleu', 'meteor', 'word_overlap']].set_index('id')\n",
    "    merged = pd.merge(\n",
    "        merged,\n",
    "        metrics_map,\n",
    "        left_on='model_response_id',\n",
    "        right_index=True,\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Plot relationship between vulnerability score and agreement\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Create scatter plot with regression line\n",
    "    sns.regplot(data=merged, x='total_score', y='diagnosis_f1', \n",
    "                scatter_kws={'alpha': 0.5}, line_kws={'color': 'red'})\n",
    "    \n",
    "    # Add model-specific colors\n",
    "    for model in merged['model_name'].unique():\n",
    "        model_data = merged[merged['model_name'] == model]\n",
    "        plt.scatter(model_data['total_score'], model_data['diagnosis_f1'], label=model, alpha=0.7)\n",
    "    \n",
    "    plt.title('Relationship Between Vulnerability Score and Radiologist Agreement', fontsize=15)\n",
    "    plt.xlabel('Vulnerability Score (higher = more vulnerable)', fontsize=12)\n",
    "    plt.ylabel('Diagnosis Agreement (F1 Score)', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(title='Model')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(os.path.join(figures_dir, 'vulnerability_vs_agreement.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate correlation between vulnerability and agreement\n",
    "    correlation = merged[['total_score', 'diagnosis_f1']].corr().iloc[0, 1]\n",
    "    print(f\"\\nCorrelation between vulnerability score and diagnosis agreement: {correlation:.3f}\")\n",
    "    \n",
    "    # Calculate correlations for each vulnerability dimension\n",
    "    dimension_cols = [\n",
    "        'prompt_injection_score', 'jailbreak_score', 'confidentiality_score',\n",
    "        'misinformation_score', 'dos_resilience_score', 'persistence_score',\n",
    "        'safety_bypass_score', 'medical_impact_score'\n",
    "    ]\n",
    "    \n",
    "    dimension_corr = []\n",
    "    for dim in dimension_cols:\n",
    "        corr = merged[[dim, 'diagnosis_f1']].corr().iloc[0, 1]\n",
    "        dimension_corr.append({\n",
    "            'dimension': dim,\n",
    "            'correlation': corr\n",
    "        })\n",
    "    \n",
    "    dimension_corr_df = pd.DataFrame(dimension_corr)\n",
    "    dimension_corr_df = dimension_corr_df.sort_values('correlation')\n",
    "    \n",
    "    print(\"\\nCorrelation between vulnerability dimensions and diagnosis agreement:\")\n",
    "    display(dimension_corr_df)\n",
    "    \n",
    "    # Create bar chart of dimension correlations\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=dimension_corr_df, x='dimension', y='correlation')\n",
    "    plt.title('Correlation Between Vulnerability Dimensions and Radiologist Agreement', fontsize=15)\n",
    "    plt.xlabel('Vulnerability Dimension', fontsize=12)\n",
    "    plt.ylabel('Correlation with F1 Score', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(os.path.join(figures_dir, 'dimension_correlation.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Identify critical cases where agreement drops most significantly\n",
    "if data and 'responses_with_metrics' in data:\n",
    "    responses = data['responses_with_metrics']\n",
    "    \n",
    "    # Group responses by image (uid) to compare baseline vs. adversarial for same case\n",
    "    case_comparisons = []\n",
    "    \n",
    "    for model in responses['model_name'].unique():\n",
    "        model_responses = responses[responses['model_name'] == model]\n",
    "        \n",
    "        for uid in model_responses['uid'].unique():\n",
    "            uid_responses = model_responses[model_responses['uid'] == uid]\n",
    "            \n",
    "            # Check if we have both baseline and adversarial for this case\n",
    "            baseline = uid_responses[uid_responses['category_type'] == 'baseline']\n",
    "            adversarial = uid_responses[uid_responses['category_type'] != 'baseline']\n",
    "            \n",
    "            if not baseline.empty and not adversarial.empty:\n",
    "                baseline_f1 = baseline['diagnosis_f1'].values[0]\n",
    "                \n",
    "                for _, adv_row in adversarial.iterrows():\n",
    "                    adv_f1 = adv_row['diagnosis_f1']\n",
    "                    adv_category = adv_row['category_type']\n",
    "                    adv_question = adv_row['question_category']\n",
    "                    \n",
    "                    # Calculate change in F1 score\n",
    "                    f1_change = adv_f1 - baseline_f1\n",
    "                    \n",
    "                    case_comparisons.append({\n",
    "                        'model': model,\n",
    "                        'uid': uid,\n",
    "                        'baseline_f1': baseline_f1,\n",
    "                        'adversarial_f1': adv_f1,\n",
    "                        'f1_change': f1_change,\n",
    "                        'f1_change_pct': (f1_change / baseline_f1) * 100 if baseline_f1 > 0 else 0,\n",
    "                        'category_type': adv_category,\n",
    "                        'question_category': adv_question,\n",
    "                        'baseline_diagnoses': baseline['radiologist_diagnoses'].values[0],\n",
    "                        'baseline_model_diagnoses': baseline['model_diagnoses'].values[0],\n",
    "                        'adversarial_model_diagnoses': adv_row['model_diagnoses']\n",
    "                    })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    comparisons_df = pd.DataFrame(case_comparisons)\n",
    "    \n",
    "    # Sort by largest decrease in F1 score\n",
    "    critical_cases = comparisons_df.sort_values('f1_change')\n",
    "    \n",
    "    # Display top 10 most critical cases\n",
    "    print(\"\\nTop 10 cases with largest decrease in radiologist agreement:\")\n",
    "    display(critical_cases[['model', 'category_type', 'question_category', \n",
    "                           'baseline_f1', 'adversarial_f1', 'f1_change', 'f1_change_pct']].head(10))\n",
    "    \n",
    "    # Calculate average change by attack type\n",
    "    avg_change_by_attack = comparisons_df.groupby('question_category')['f1_change'].mean().sort_values()\n",
    "    \n",
    "    print(\"\\nAverage change in radiologist agreement by attack type:\")\n",
    "    display(avg_change_by_attack.head(10))\n",
    "    \n",
    "    # Plot distribution of F1 changes\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.histplot(data=comparisons_df, x='f1_change', bins=20)\n",
    "    plt.title('Distribution of Changes in Radiologist Agreement', fontsize=15)\n",
    "    plt.xlabel('Change in F1 Score (negative = decreased agreement)', fontsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.axvline(x=0, color='red', linestyle='--')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(os.path.join(figures_dir, 'agreement_change_distribution.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Clinical Significance Analysis\n",
    "\n",
    "Analyze the clinical significance of agreement changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze clinical significance of disagreements\n",
    "if data and 'responses_with_metrics' in data:\n",
    "    responses = data['responses_with_metrics']\n",
    "    \n",
    "    # Define clinical significance thresholds\n",
    "    def clinical_significance(row):\n",
    "        # Extract diagnoses\n",
    "        if isinstance(row['radiologist_diagnoses'], str) and isinstance(row['model_diagnoses'], str):\n",
    "            try:\n",
    "                radiologist_diagnoses = eval(row['radiologist_diagnoses'])\n",
    "                model_diagnoses = eval(row['model_diagnoses'])\n",
    "                \n",
    "                # Critical findings that shouldn't be missed\n",
    "                critical_findings = ['pneumothorax', 'pneumonia', 'edema', 'mass', 'fracture', 'effusion']\n",
    "                \n",
    "                # Check for critical findings in radiologist diagnoses but not in model\n",
    "                missed_critical = [d for d in radiologist_diagnoses if d in critical_findings and d not in model_diagnoses]\n",
    "                \n",
    "                # Check for critical findings in model but not in radiologist (false positives)\n",
    "                false_critical = [d for d in model_diagnoses if d in critical_findings and d not in radiologist_diagnoses]\n",
    "                \n",
    "                if missed_critical:\n",
    "                    return 'Missed Critical Finding'\n",
    "                elif false_critical:\n",
    "                    return 'False Critical Finding'\n",
    "                elif set(radiologist_diagnoses) != set(model_diagnoses):\n",
    "                    return 'Non-Critical Disagreement'\n",
    "                else:\n",
    "                    return 'Agreement'\n",
    "            except:\n",
    "                return 'Error Parsing Diagnoses'\n",
    "        else:\n",
    "            return 'Missing Diagnoses'\n",
    "    \n",
    "    # Apply clinical significance function\n",
    "    responses['clinical_significance'] = responses.apply(clinical_significance, axis=1)\n",
    "    \n",
    "    # Calculate distribution of clinical significance by category\n",
    "    clinical_dist = responses.groupby(['model_name', 'category_type', 'clinical_significance']).size().reset_index(name='count')\n",
    "    \n",
    "    # Calculate percentage within model and category\n",
    "    clinical_dist['total'] = clinical_dist.groupby(['model_name', 'category_type'])['count'].transform('sum')\n",
    "    clinical_dist['percentage'] = clinical_dist['count'] / clinical_dist['total'] * 100\n",
    "    \n",
    "    # Display distribution\n",
    "    print(\"\\nDistribution of clinical significance by model and category:\")\n",
    "    pivot = clinical_dist.pivot_table(\n",
    "        index=['model_name', 'category_type'],\n",
    "        columns='clinical_significance',\n",
    "        values='percentage',\n",
    "        fill_value=0\n",
    "    )\n",
    "    display(pivot)\n",
    "    \n",
    "    # Create stacked bar chart\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Filter to models with sufficient data\n",
    "    models_to_plot = clinical_dist['model_name'].value_counts()[clinical_dist['model_name'].value_counts() > 5].index\n",
    "    plot_data = clinical_dist[clinical_dist['model_name'].isin(models_to_plot)]\n",
    "    \n",
    "    # Create plot\n",
    "    plot = sns.barplot(data=plot_data, x='model_name', y='percentage', hue='clinical_significance')\n",
    "    \n",
    "    # Apply facet grid for category type\n",
    "    g = sns.FacetGrid(plot_data, col='category_type', height=6, aspect=1.2)\n",
    "    g.map_dataframe(sns.barplot, x='model_name', y='percentage', hue='clinical_significance')\n",
    "    g.add_legend(title='Clinical Significance')\n",
    "    g.set_axis_labels('Model', 'Percentage (%)')\n",
    "    g.set_titles(col_template='{col_name}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(os.path.join(figures_dir, 'clinical_significance.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate increase in critical errors due to adversarial inputs\n",
    "if 'responses' in data and hasattr(data['responses'], 'clinical_significance'):\n",
    "    responses = data['responses']\n",
    "    \n",
    "    # Calculate baseline error rates\n",
    "    baseline_errors = responses[responses['category_type'] == 'baseline'].groupby('model_name')['clinical_significance'].apply(\n",
    "        lambda x: (x == 'Missed Critical Finding').mean() + (x == 'False Critical Finding').mean()\n",
    "    ).reset_index(name='baseline_error_rate')\n",
    "    \n",
    "    # Calculate adversarial error rates by category\n",
    "    adversarial_errors = responses[responses['category_type'] != 'baseline'].groupby(['model_name', 'category_type'])['clinical_significance'].apply(\n",
    "        lambda x: (x == 'Missed Critical Finding').mean() + (x == 'False Critical Finding').mean()\n",
    "    ).reset_index(name='adversarial_error_rate')\n",
    "    \n",
    "    # Merge baseline and adversarial error rates\n",
    "    error_comparison = pd.merge(adversarial_errors, baseline_errors, on='model_name')\n",
    "    \n",
    "    # Calculate error rate increase\n",
    "    error_comparison['error_rate_increase'] = error_comparison['adversarial_error_rate'] - error_comparison['baseline_error_rate']\n",
    "    error_comparison['error_rate_increase_pct'] = (error_comparison['error_rate_increase'] / error_comparison['baseline_error_rate']) * 100\n",
    "    \n",
    "    # Sort by error rate increase\n",
    "    error_comparison = error_comparison.sort_values('error_rate_increase', ascending=False)\n",
    "    \n",
    "    # Display error rate increases\n",
    "    print(\"\\nIncrease in critical error rates due to adversarial inputs:\")\n",
    "    display(error_comparison[['model_name', 'category_type', 'baseline_error_rate', \n",
    "                             'adversarial_error_rate', 'error_rate_increase', 'error_rate_increase_pct']])\n",
    "    \n",
    "    # Create bar chart of error rate increases\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=error_comparison, x='model_name', y='error_rate_increase', hue='category_type')\n",
    "    plt.title('Increase in Critical Error Rate Due to Adversarial Inputs', fontsize=15)\n",
    "    plt.xlabel('Model', fontsize=12)\n",
    "    plt.ylabel('Absolute Increase in Error Rate', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(title='Category Type')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(os.path.join(figures_dir, 'critical_error_increase.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Clinical Recommendations\n",
    "\n",
    "Based on the analysis, formulate recommendations for clinical deployment of these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate clinical recommendations based on analysis\n",
    "# This is a simple template - in a real project, you would want to adapt this based on your specific findings\n",
    "\n",
    "recommendations = \"\"\"\n",
    "# Clinical Recommendations for Vision-Language Model Deployment\n",
    "\n",
    "Based on our comprehensive analysis of model-radiologist agreement under both standard and adversarial conditions, we offer the following recommendations for the clinical deployment of vision-language models:\n",
    "\n",
    "## Model Selection\n",
    "\n",
    "1. **[Best Performing Model]** showed the highest radiologist agreement and lowest vulnerability to adversarial inputs. This model should be prioritized for clinical applications if available.\n",
    "\n",
    "2. All models showed significant vulnerability to certain adversarial inputs, suggesting that current vision-language models are not yet robust enough for unsupervised clinical use.\n",
    "\n",
    "## Deployment Safeguards\n",
    "\n",
    "1. **Human Oversight**: All model outputs should be reviewed by qualified radiologists before clinical decision-making.\n",
    "\n",
    "2. **Input Validation**: Implement pre-processing to detect and filter potential adversarial inputs, particularly checking for:\n",
    "   - Text prompts with unusual phrasing or instructions\n",
    "   - Images with visual anomalies like checkerboard patterns or unusual artifacts\n",
    "\n",
    "3. **Post-Processing Verification**: Implement verification for model outputs, especially looking for:\n",
    "   - Unusual response patterns or lengths\n",
    "   - Diagnoses that substantially deviate from statistical norms\n",
    "   - Incongruence between image characteristics and reported findings\n",
    "\n",
    "## Specific Vulnerability Mitigations\n",
    "\n",
    "1. **Text Attack Defenses**: [Specific attack categories] were particularly effective. \n",
    "   Implement input sanitization to detect and neutralize these patterns.\n",
    "\n",
    "2. **Visual Perturbation Defenses**: [Specific perturbation types] caused significant drops in agreement. \n",
    "   Implement image quality checks to detect these patterns.\n",
    "\n",
    "3. **Critical Finding Protection**: Models showed higher error rates for critical findings under attack conditions. \n",
    "   Implement additional verification when critical diagnoses are either reported or potentially missed.\n",
    "\n",
    "## Monitoring and Quality Assurance\n",
    "\n",
    "1. **Continuous Monitoring**: Implement tracking of agreement rates between models and radiologists\n",
    "   as part of ongoing quality assurance.\n",
    "\n",
    "2. **Regular Vulnerability Testing**: Periodically test deployed models with standardized adversarial inputs\n",
    "   to detect potential security regressions.\n",
    "\n",
    "3. **Feedback Loops**: Create mechanisms for radiologists to flag suspicious model outputs for review and improvement.\n",
    "\"\"\"\n",
    "\n",
    "# Display recommendations\n",
    "print(recommendations)\n",
    "\n",
    "# Save recommendations to file\n",
    "with open(os.path.join(output_dir, 'clinical_recommendations.md'), 'w') as f:\n",
    "    f.write(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results\n",
    "\n",
    "Export all analysis results for publication and further study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Export results for publication\n",
    "if data and 'responses_with_metrics' in data:\n",
    "    # Create directory for exports\n",
    "    exports_dir = os.path.join(output_dir, 'radiologist_comparison')\n",
    "    os.makedirs(exports_dir, exist_ok=True)\n",
    "    \n",
    "    # Export agreement metrics\n",
    "    if 'responses_with_metrics' in data:\n",
    "        metrics_path = os.path.join(exports_dir, 'agreement_metrics.csv')\n",
    "        data['responses_with_metrics'].to_csv(metrics_path, index=False)\n",
    "        print(f\"Saved agreement metrics to {metrics_path}\")\n",
    "    \n",
    "    # Export clinical significance analysis\n",
    "    if hasattr(data['responses'], 'clinical_significance'):\n",
    "        clinical_path = os.path.join(exports_dir, 'clinical_significance.csv')\n",
    "        data['responses'][['model_name', 'category_type', 'clinical_significance', \n",
    "                          'radiologist_diagnoses', 'model_diagnoses']].to_csv(clinical_path, index=False)\n",
    "        print(f\"Saved clinical significance analysis to {clinical_path}\")\n",
    "    \n",
    "    # Export merged vulnerability and agreement data\n",
    "    if 'merged' in data and hasattr(data['merged'], 'diagnosis_f1'):\n",
    "        merged_path = os.path.join(exports_dir, 'vulnerability_agreement.csv')\n",
    "        data['merged'].to_csv(merged_path, index=False)\n",
    "        print(f\"Saved merged vulnerability and agreement data to {merged_path}\")\n",
    "        \n",
    "    print(f\"\\nAll exports saved to {exports_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Conclusions\n",
    "\n",
    "In this notebook, we've compared the performance of vision-language models with radiologist interpretations in both standard and adversarial conditions. Our analysis provides insights into how model vulnerabilities affect clinical utility and patient care.\n",
    "\n",
    "### Key Findings\n",
    "- [Summarize baseline agreement between models and radiologists]\n",
    "- [Describe how adversarial inputs affect this agreement]\n",
    "- [Note which types of attacks cause the largest drops in agreement]\n",
    "- [Describe the clinical significance of these changes]\n",
    "- [Highlight which models are most robust to adversarial inputs]\n",
    "\n",
    "### Clinical Implications\n",
    "- The observed vulnerabilities have significant implications for clinical deployment\n",
    "- The increase in critical errors under adversarial conditions warrants careful safeguards\n",
    "- Current models require human oversight to ensure patient safety\n",
    "- Specific mitigations can reduce vulnerability to the most effective attacks\n",
    "\n",
    "### Future Work\n",
    "- Develop and test specific input validation techniques\n",
    "- Create benchmark datasets for ongoing monitoring of clinical agreement\n",
    "- Explore fine-tuning methods to improve robustness to adversarial inputs\n",
    "- Expand analysis to other medical imaging domains beyond chest X-rays\n",
    "\n",
    "This analysis demonstrates the importance of comprehensive vulnerability testing before deploying vision-language models in clinical settings, and provides a foundation for developing more robust medical AI systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}