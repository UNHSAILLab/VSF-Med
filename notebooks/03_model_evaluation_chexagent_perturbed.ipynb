{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation: CheXagent Performance on Perturbed Images\n",
    "\n",
    "**Author:** [Your Name]\n",
    "\n",
    "**Date:** [Current Date]\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook is part of the VSF-Med (Vulnerability Scoring Framework for Medical Vision-Language Models) research project. It evaluates the StanfordAIMI/CheXagent-8b model on visually perturbed chest X-ray images to assess the model's robustness to visual adversarial attacks.\n",
    "\n",
    "### Purpose\n",
    "- Evaluate CheXagent's performance when presented with visually perturbed medical images\n",
    "- Test multiple visual perturbation methods with varying parameters\n",
    "- Compare results with baseline performance on unmodified images\n",
    "- Identify vulnerabilities in visual processing capabilities\n",
    "\n",
    "### Workflow\n",
    "1. Set up the environment and load the CheXagent model\n",
    "2. Apply various visual perturbations to chest X-ray images\n",
    "3. Process perturbed images through the model\n",
    "4. Store responses in the database for vulnerability analysis\n",
    "5. Compare responses to baseline performance\n",
    "\n",
    "### Perturbation Methods\n",
    "We use six visual perturbation techniques in this evaluation:\n",
    "1. **Gaussian Noise**: Adding random noise with different standard deviations\n",
    "2. **Checkerboard Overlay**: Placing checkerboard patterns over portions of the image\n",
    "3. **Moir√© Patterns**: Adding interference-like patterns with varying frequencies\n",
    "4. **Random Arrow Artifacts**: Overlaying directional indicators that might mislead interpretation\n",
    "5. **Steganographic Hiding**: Embedding hidden information in the image\n",
    "6. **LSB Extraction**: Manipulating least significant bits to create subtle artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "### 1.1 Install Required Libraries\n",
    "\n",
    "First, we'll install all necessary libraries for model inference, image processing, and database operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "!pip install torch transformers pillow sqlalchemy psycopg2-binary pandas numpy matplotlib python-dotenv tqdm pyyaml opencv-python scikit-image stegano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import datetime\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Add the src directory to the path for importing custom modules\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Import custom image perturbation module\n",
    "from src.utils.perturbations.image_perturbations import ImagePerturbation\n",
    "\n",
    "# Check platform for environment-specific settings\n",
    "import platform\n",
    "operating_system = platform.system()\n",
    "print(f\"Operating System: {operating_system}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Configuration Setup\n",
    "\n",
    "Load configuration from YAML file and set up environment-specific settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load configuration\n",
    "config_path = os.path.join(parent_dir, 'src', 'config', 'default_config.yaml')\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Configure paths based on operating system\n",
    "if operating_system == 'Darwin':  # macOS\n",
    "    base_dir = os.path.expanduser('~/data/mimic-cxr-jpg/2.1.0/files')\n",
    "    output_dir = os.path.expanduser('~/data/vsf-med/output')\n",
    "    perturb_dir = os.path.expanduser('~/data/vsf-med/perturbed_files')\n",
    "elif operating_system == 'Linux':\n",
    "    base_dir = '/data/mimic-cxr-jpg/2.1.0/files'\n",
    "    output_dir = '/data/vsf-med/output'\n",
    "    perturb_dir = '/data/vsf-med/perturbed_files'\n",
    "else:  # Windows or other\n",
    "    base_dir = config['paths']['data_dir'].replace('${HOME}', os.path.expanduser('~'))\n",
    "    output_dir = config['paths']['output_dir'].replace('${HOME}', os.path.expanduser('~'))\n",
    "    perturb_dir = config['paths']['perturbation_dir'].replace('${HOME}', os.path.expanduser('~'))\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(perturb_dir, exist_ok=True)\n",
    "\n",
    "# Create subdirectories for each perturbation type\n",
    "perturb_types = ['gaussian_noise', 'checkerboard', 'moire', 'arrow', 'stegano', 'lsb']\n",
    "perturb_dirs = {}\n",
    "for ptype in perturb_types:\n",
    "    perturb_dirs[ptype] = os.path.join(perturb_dir, ptype)\n",
    "    os.makedirs(perturb_dirs[ptype], exist_ok=True)\n",
    "\n",
    "# Set up database connection\n",
    "db_config = config['database']\n",
    "db_password = os.environ.get('DB_PASSWORD', '')\n",
    "CONNECTION_STRING = f\"postgresql://{db_config['user']}:{db_password}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(CONNECTION_STRING)\n",
    "\n",
    "print(f\"Data directory: {base_dir}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Perturbation directory: {perturb_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Database Functions\n",
    "\n",
    "Set up functions to interact with the database for fetching questions and storing model responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def fetch_questions(condition='original', limit=100):\n",
    "    \"\"\"\n",
    "    Fetch questions from the database based on condition.\n",
    "    \n",
    "    Args:\n",
    "        condition (str): Type of questions to fetch (original, adversarial, etc.)\n",
    "        limit (int): Maximum number of questions to fetch\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the questions\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    SELECT id, question_id, condition, text, image \n",
    "    FROM mimicxp.mimic_all_qns \n",
    "    WHERE condition = '{condition}' \n",
    "    LIMIT {limit}\n",
    "    \"\"\"\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        df = pd.read_sql(query, conn)\n",
    "    \n",
    "    print(f\"Fetched {len(df)} {condition} questions from database\")\n",
    "    return df\n",
    "\n",
    "def store_model_response(uid, question_id, question, question_category, \n",
    "                         actual_answer, model_name, model_answer, image_link):\n",
    "    \"\"\"\n",
    "    Store model response in the database.\n",
    "    \n",
    "    Args:\n",
    "        uid (str): Unique identifier for the source image\n",
    "        question_id (str): Question ID\n",
    "        question (str): The question text\n",
    "        question_category (str): Category of question (original, visual_perturb, text_attack)\n",
    "        actual_answer (str): Ground truth answer (if available)\n",
    "        model_name (str): Name of the model\n",
    "        model_answer (str): Model's response\n",
    "        image_link (str): Path to the image file\n",
    "        \n",
    "    Returns:\n",
    "        int: ID of the inserted record\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    INSERT INTO mimicxp.model_responses_r2 \n",
    "    (uid, question_id, question, question_category, actual_answer, model_name, model_answer, image_link, created_at) \n",
    "    VALUES (:uid, :question_id, :question, :question_category, :actual_answer, :model_name, :model_answer, :image_link, NOW()) \n",
    "    RETURNING id\n",
    "    \"\"\"\n",
    "    \n",
    "    params = {\n",
    "        'uid': uid,\n",
    "        'question_id': str(question_id),\n",
    "        'question': question,\n",
    "        'question_category': question_category,\n",
    "        'actual_answer': actual_answer,\n",
    "        'model_name': model_name,\n",
    "        'model_answer': model_answer,\n",
    "        'image_link': image_link\n",
    "    }\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(query), params)\n",
    "        conn.commit()\n",
    "        record_id = result.fetchone()[0]\n",
    "    \n",
    "    return record_id\n",
    "\n",
    "def store_perturbation_metadata(original_image_path, perturbed_image_path, perturbation_type, parameters, ssim_value, psnr=None):\n",
    "    \"\"\"\n",
    "    Store perturbation metadata in the database.\n",
    "    \n",
    "    Args:\n",
    "        original_image_path (str): Path to the original image\n",
    "        perturbed_image_path (str): Path to the perturbed image\n",
    "        perturbation_type (str): Type of perturbation\n",
    "        parameters (dict): Perturbation parameters\n",
    "        ssim_value (float): Structural Similarity Index\n",
    "        psnr (float, optional): Peak Signal-to-Noise Ratio\n",
    "        \n",
    "    Returns:\n",
    "        int: ID of the inserted record\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    INSERT INTO mimicxp.perturbation_metadata \n",
    "    (original_image_path, perturbed_image_path, perturbation_type, parameters, ssim, psnr, created_at) \n",
    "    VALUES (:original_image_path, :perturbed_image_path, :perturbation_type, :parameters, :ssim, :psnr, NOW()) \n",
    "    RETURNING id\n",
    "    \"\"\"\n",
    "    \n",
    "    params = {\n",
    "        'original_image_path': original_image_path,\n",
    "        'perturbed_image_path': perturbed_image_path,\n",
    "        'perturbation_type': perturbation_type,\n",
    "        'parameters': json.dumps(parameters),\n",
    "        'ssim': ssim_value,\n",
    "        'psnr': psnr\n",
    "    }\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(query), params)\n",
    "        conn.commit()\n",
    "        record_id = result.fetchone()[0]\n",
    "    \n",
    "    return record_id\n",
    "\n",
    "def check_existing_response(uid, question_id, model_name, question_category):\n",
    "    \"\"\"\n",
    "    Check if a response already exists in the database.\n",
    "    \n",
    "    Args:\n",
    "        uid (str): Unique identifier for the source image\n",
    "        question_id (str): Question ID\n",
    "        model_name (str): Name of the model\n",
    "        question_category (str): Category of question\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if response exists, False otherwise\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT COUNT(*) FROM mimicxp.model_responses_r2 \n",
    "    WHERE uid = :uid AND question_id = :question_id AND model_name = :model_name AND question_category = :question_category\n",
    "    \"\"\"\n",
    "    \n",
    "    params = {\n",
    "        'uid': uid,\n",
    "        'question_id': str(question_id),\n",
    "        'model_name': model_name,\n",
    "        'question_category': question_category\n",
    "    }\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(query), params)\n",
    "        count = result.fetchone()[0]\n",
    "    \n",
    "    return count > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Setup\n",
    "\n",
    "Load the CheXagent model and set up for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def setup_model():\n",
    "    \"\"\"\n",
    "    Set up the CheXagent model for inference.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (model, processor)\n",
    "    \"\"\"\n",
    "    model_id = \"StanfordAIMI/CheXagent-8b\"\n",
    "    print(f\"Loading model: {model_id}\")\n",
    "    \n",
    "    # Check for GPU availability\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load model and processor\n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "        device_map=\"auto\" if device == \"cuda\" else None\n",
    "    )\n",
    "    \n",
    "    return model, processor\n",
    "\n",
    "# Load the model\n",
    "try:\n",
    "    model, processor = setup_model()\n",
    "    print(\"Model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    # For demonstration, continue execution without model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Perturbation Functions\n",
    "\n",
    "Define functions for generating perturbed versions of medical images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def apply_perturbation(image_path, perturbation_type, output_dir, params=None):\n",
    "    \"\"\"\n",
    "    Apply a perturbation to an image.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the original image\n",
    "        perturbation_type (str): Type of perturbation to apply\n",
    "        output_dir (str): Directory to save the perturbed image\n",
    "        params (dict, optional): Parameters for the perturbation\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (perturbed_image_path, ssim_value)\n",
    "    \"\"\"\n",
    "    # Read the original image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Error reading image: {image_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Set default parameters if none provided\n",
    "    if params is None:\n",
    "        params = {}\n",
    "    \n",
    "    # Apply the perturbation\n",
    "    perturbed_img = None\n",
    "    \n",
    "    if perturbation_type == 'gaussian_noise':\n",
    "        stddev = params.get('stddev', 25)\n",
    "        perturbed_img = ImagePerturbation.add_gaussian_noise(img, stddev=stddev)\n",
    "        \n",
    "    elif perturbation_type == 'checkerboard':\n",
    "        patch_size = params.get('patch_size', 100)\n",
    "        square_size = params.get('square_size', 25)\n",
    "        fill = params.get('fill', 128)\n",
    "        tiled = params.get('tiled', False)\n",
    "        checker = ImagePerturbation.make_checkerboard(patch_size, square_size, fill)\n",
    "        perturbed_img = ImagePerturbation.overlay_checkerboard(img, checker, tiled)\n",
    "        \n",
    "    elif perturbation_type == 'moire':\n",
    "        freq = params.get('freq', 0.1)\n",
    "        alpha = params.get('alpha', 0.3)\n",
    "        perturbed_img = ImagePerturbation.overlay_moire_pattern(img, freq=freq, alpha=alpha)\n",
    "        \n",
    "    elif perturbation_type == 'arrow':\n",
    "        perturbed_img = ImagePerturbation.add_random_arrow(img)\n",
    "        \n",
    "    elif perturbation_type == 'compression':\n",
    "        quality = params.get('quality', 30)\n",
    "        perturbed_img = ImagePerturbation.simulate_compression_artifacts(img, quality=quality)\n",
    "        \n",
    "    else:\n",
    "        # For other perturbation types, use the generic perturb_image method\n",
    "        perturbed_img = ImagePerturbation.perturb_image(img, technique=perturbation_type, **params)\n",
    "    \n",
    "    if perturbed_img is None:\n",
    "        print(f\"Error applying perturbation: {perturbation_type}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Calculate SSIM\n",
    "    ssim_value = ImagePerturbation.compute_ssim(img, perturbed_img)\n",
    "    \n",
    "    # Save the perturbed image\n",
    "    filename = os.path.basename(image_path)\n",
    "    base_name, ext = os.path.splitext(filename)\n",
    "    perturbed_filename = f\"{base_name}_{perturbation_type}{ext}\"\n",
    "    perturbed_path = os.path.join(output_dir, perturbed_filename)\n",
    "    cv2.imwrite(perturbed_path, perturbed_img)\n",
    "    \n",
    "    return perturbed_path, ssim_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def load_image(image_path):\n",
    "    \"\"\"\n",
    "    Load an image from file.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "        \n",
    "    Returns:\n",
    "        PIL.Image: Loaded image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_response(model, processor, image, prompt):\n",
    "    \"\"\"\n",
    "    Generate a response from the model for the given image and prompt.\n",
    "    \n",
    "    Args:\n",
    "        model: CheXagent model\n",
    "        processor: CheXagent processor\n",
    "        image (PIL.Image): Input image\n",
    "        prompt (str): Text prompt\n",
    "        \n",
    "    Returns:\n",
    "        str: Model's response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Process the image and prompt\n",
    "        inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Generate response\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=512,\n",
    "                temperature=0.1,\n",
    "                do_sample=True,\n",
    "                top_p=0.9,\n",
    "            )\n",
    "        \n",
    "        # Decode and clean the response\n",
    "        response = processor.decode(output[0], skip_special_tokens=True)\n",
    "        response = response.replace(prompt, \"\").strip()\n",
    "        \n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"\n",
    "    Clear GPU memory to prevent out-of-memory errors during batch processing.\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"Cleared GPU memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Image Perturbation Creation\n",
    "\n",
    "Create perturbed versions of medical images for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define perturbation types and parameters to test\n",
    "perturbation_configs = {\n",
    "    'gaussian_noise': [\n",
    "        {'stddev': 15},\n",
    "        {'stddev': 25}\n",
    "    ],\n",
    "    'checkerboard': [\n",
    "        {'patch_size': 100, 'square_size': 25, 'fill': 128, 'tiled': False},\n",
    "        {'patch_size': 100, 'square_size': 25, 'fill': 128, 'tiled': True}\n",
    "    ],\n",
    "    'moire': [\n",
    "        {'freq': 0.1, 'alpha': 0.3},\n",
    "        {'freq': 0.2, 'alpha': 0.4}\n",
    "    ],\n",
    "    'arrow': [{}]  # No parameters needed\n",
    "}\n",
    "\n",
    "# Fetch original questions for perturbation\n",
    "questions = fetch_questions(condition='original', limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_perturbed_images(questions_df, perturbation_configs):\n",
    "    \"\"\"\n",
    "    Create perturbed versions of images for all questions.\n",
    "    \n",
    "    Args:\n",
    "        questions_df (pd.DataFrame): DataFrame of questions with image paths\n",
    "        perturbation_configs (dict): Dictionary of perturbation types and parameters\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with perturbation metadata\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for _, row in tqdm(questions_df.iterrows(), total=len(questions_df)):\n",
    "        # Get image path\n",
    "        image_rel_path = row['image']\n",
    "        image_full_path = os.path.join(base_dir, image_rel_path)\n",
    "        \n",
    "        if not os.path.exists(image_full_path):\n",
    "            print(f\"Image not found: {image_full_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Apply each perturbation type with different parameters\n",
    "        for perturb_type, params_list in perturbation_configs.items():\n",
    "            perturb_type_dir = perturb_dirs[perturb_type]\n",
    "            \n",
    "            for params in params_list:\n",
    "                # Apply perturbation\n",
    "                perturbed_path, ssim_value = apply_perturbation(\n",
    "                    image_path=image_full_path,\n",
    "                    perturbation_type=perturb_type,\n",
    "                    output_dir=perturb_type_dir,\n",
    "                    params=params\n",
    "                )\n",
    "                \n",
    "                if perturbed_path is None or ssim_value is None:\n",
    "                    continue\n",
    "                \n",
    "                # Get relative path for database storage\n",
    "                perturbed_rel_path = os.path.relpath(perturbed_path, perturb_dir)\n",
    "                perturbed_rel_path = f\"perturbed_files/{perturbed_rel_path}\"\n",
    "                \n",
    "                # Store metadata in database\n",
    "                try:\n",
    "                    metadata_id = store_perturbation_metadata(\n",
    "                        original_image_path=image_rel_path,\n",
    "                        perturbed_image_path=perturbed_rel_path,\n",
    "                        perturbation_type=perturb_type,\n",
    "                        parameters=params,\n",
    "                        ssim_value=ssim_value\n",
    "                    )\n",
    "                    \n",
    "                    # Store result for return\n",
    "                    results.append({\n",
    "                        'metadata_id': metadata_id,\n",
    "                        'question_id': row['question_id'],\n",
    "                        'original_image': image_rel_path,\n",
    "                        'perturbed_image': perturbed_rel_path,\n",
    "                        'perturbation_type': perturb_type,\n",
    "                        'parameters': params,\n",
    "                        'ssim': ssim_value\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error storing perturbation metadata: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create perturbed images\n",
    "# Note: This may take some time depending on the number of images and perturbations\n",
    "perturbation_results = create_perturbed_images(questions, perturbation_configs)\n",
    "\n",
    "# Display some of the results\n",
    "if not perturbation_results.empty:\n",
    "    print(f\"Created {len(perturbation_results)} perturbed images\")\n",
    "    print(\"\\nPerturbation types:\")\n",
    "    print(perturbation_results['perturbation_type'].value_counts())\n",
    "    print(\"\\nSSIM statistics:\")\n",
    "    print(f\"Min SSIM: {perturbation_results['ssim'].min():.4f}\")\n",
    "    print(f\"Mean SSIM: {perturbation_results['ssim'].mean():.4f}\")\n",
    "    print(f\"Max SSIM: {perturbation_results['ssim'].max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize some example perturbations\n",
    "def visualize_perturbation(original_path, perturbed_path, perturbation_type, ssim_value):\n",
    "    \"\"\"\n",
    "    Visualize an original image and its perturbed version.\n",
    "    \n",
    "    Args:\n",
    "        original_path (str): Path to the original image\n",
    "        perturbed_path (str): Path to the perturbed image\n",
    "        perturbation_type (str): Type of perturbation\n",
    "        ssim_value (float): SSIM value\n",
    "    \"\"\"\n",
    "    # Read images\n",
    "    original_img = cv2.imread(os.path.join(base_dir, original_path))\n",
    "    perturbed_img = cv2.imread(os.path.join(perturb_dir, perturbed_path.replace('perturbed_files/', '')))\n",
    "    \n",
    "    if original_img is None or perturbed_img is None:\n",
    "        print(\"Error reading images for visualization\")\n",
    "        return\n",
    "    \n",
    "    # Convert from BGR to RGB for display\n",
    "    original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
    "    perturbed_img = cv2.cvtColor(perturbed_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Display original image\n",
    "    ax1.imshow(original_img)\n",
    "    ax1.set_title('Original Image')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Display perturbed image\n",
    "    ax2.imshow(perturbed_img)\n",
    "    ax2.set_title(f'Perturbed ({perturbation_type}, SSIM: {ssim_value:.4f})')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize examples of each perturbation type\n",
    "if not perturbation_results.empty:\n",
    "    for perturb_type in perturbation_configs.keys():\n",
    "        example = perturbation_results[perturbation_results['perturbation_type'] == perturb_type].iloc[0]\n",
    "        visualize_perturbation(\n",
    "            original_path=example['original_image'],\n",
    "            perturbed_path=example['perturbed_image'],\n",
    "            perturbation_type=example['perturbation_type'],\n",
    "            ssim_value=example['ssim']\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation on Perturbed Images\n",
    "\n",
    "Process perturbed images through the model and compare with baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def process_perturbed_images(perturbation_df, questions_df, model_name=\"StanfordAIMI/CheXagent-8b\", batch_size=5, total_limit=20):\n",
    "    \"\"\"\n",
    "    Process perturbed images through the model.\n",
    "    \n",
    "    Args:\n",
    "        perturbation_df (pd.DataFrame): DataFrame with perturbation metadata\n",
    "        questions_df (pd.DataFrame): DataFrame with questions\n",
    "        model_name (str): Name of the model\n",
    "        batch_size (int): Number of images to process before clearing memory\n",
    "        total_limit (int): Maximum number of images to process\n",
    "        \n",
    "    Returns:\n",
    "        list: List of response records\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    processed_count = 0\n",
    "    \n",
    "    # Merge perturbation data with questions\n",
    "    merged_df = pd.merge(\n",
    "        perturbation_df,\n",
    "        questions_df[['question_id', 'id', 'text']],\n",
    "        on='question_id'\n",
    "    )\n",
    "    \n",
    "    # Limit the number of images to process\n",
    "    merged_df = merged_df.head(total_limit)\n",
    "    \n",
    "    for batch_start in range(0, len(merged_df), batch_size):\n",
    "        # Get batch of images\n",
    "        batch_end = min(batch_start + batch_size, len(merged_df))\n",
    "        batch = merged_df.iloc[batch_start:batch_end]\n",
    "        \n",
    "        print(f\"Processing batch {batch_start//batch_size + 1}/{(len(merged_df)-1)//batch_size + 1}\")\n",
    "        \n",
    "        for _, row in tqdm(batch.iterrows(), total=len(batch)):\n",
    "            uid = row['id']\n",
    "            question_id = row['question_id']\n",
    "            question = row['text']\n",
    "            perturbed_image_path = row['perturbed_image']\n",
    "            perturbation_type = row['perturbation_type']\n",
    "            \n",
    "            # Form question category\n",
    "            question_category = f\"visual_perturb_{perturbation_type}\"\n",
    "            \n",
    "            # Check if this has already been evaluated\n",
    "            if check_existing_response(uid, question_id, model_name, question_category):\n",
    "                print(f\"Skipping already processed question {question_id}\")\n",
    "                continue\n",
    "            \n",
    "            # Form full image path\n",
    "            full_image_path = os.path.join(perturb_dir, perturbed_image_path.replace('perturbed_files/', ''))\n",
    "            \n",
    "            # Check if image exists\n",
    "            if not os.path.exists(full_image_path):\n",
    "                print(f\"Image not found: {full_image_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Load image\n",
    "            img = load_image(full_image_path)\n",
    "            if img is None:\n",
    "                print(f\"Skipping image {perturbed_image_path} due to loading error\")\n",
    "                continue\n",
    "                \n",
    "            # Generate response\n",
    "            response = generate_response(model, processor, img, question)\n",
    "            \n",
    "            # Store response in database\n",
    "            try:\n",
    "                record_id = store_model_response(\n",
    "                    uid=uid,\n",
    "                    question_id=question_id,\n",
    "                    question=question,\n",
    "                    question_category=question_category,\n",
    "                    actual_answer=None,  # No ground truth available\n",
    "                    model_name=model_name,\n",
    "                    model_answer=response,\n",
    "                    image_link=perturbed_image_path\n",
    "                )\n",
    "                \n",
    "                results.append({\n",
    "                    'record_id': record_id,\n",
    "                    'question_id': question_id,\n",
    "                    'question': question,\n",
    "                    'perturbation_type': perturbation_type,\n",
    "                    'response': response\n",
    "                })\n",
    "                \n",
    "                processed_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error storing response: {e}\")\n",
    "        \n",
    "        # Clear GPU memory after each batch\n",
    "        clear_gpu_memory()\n",
    "    \n",
    "    print(f\"Processed {processed_count} perturbed images\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process perturbed images through the model\n",
    "if not perturbation_results.empty:\n",
    "    perturbed_results = process_perturbed_images(\n",
    "        perturbation_df=perturbation_results,\n",
    "        questions_df=questions,\n",
    "        model_name=\"StanfordAIMI/CheXagent-8b\",\n",
    "        batch_size=5,\n",
    "        total_limit=20\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparative Analysis\n",
    "\n",
    "Compare responses from original and perturbed images to analyze the effect of perturbations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def fetch_comparative_responses(model_name=\"StanfordAIMI/CheXagent-8b\", limit=100):\n",
    "    \"\"\"\n",
    "    Fetch baseline and perturbed responses for comparative analysis.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Name of the model\n",
    "        limit (int): Maximum number of responses to fetch\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing paired responses\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    WITH original_responses AS (\n",
    "        SELECT uid, question_id, question, model_answer, image_link\n",
    "        FROM mimicxp.model_responses_r2\n",
    "        WHERE model_name = '{model_name}' AND question_category = 'original'\n",
    "    ),\n",
    "    perturbed_responses AS (\n",
    "        SELECT uid, question_id, question_category, model_answer, image_link\n",
    "        FROM mimicxp.model_responses_r2\n",
    "        WHERE model_name = '{model_name}' AND question_category LIKE 'visual_perturb_%'\n",
    "    )\n",
    "    SELECT \n",
    "        o.uid, o.question_id, o.question, \n",
    "        o.model_answer AS original_answer,\n",
    "        p.model_answer AS perturbed_answer,\n",
    "        p.question_category,\n",
    "        o.image_link AS original_image,\n",
    "        p.image_link AS perturbed_image\n",
    "    FROM original_responses o\n",
    "    JOIN perturbed_responses p ON o.uid = p.uid AND o.question_id = p.question_id\n",
    "    LIMIT {limit}\n",
    "    \"\"\"\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        df = pd.read_sql(query, conn)\n",
    "    \n",
    "    print(f\"Fetched {len(df)} paired responses from database\")\n",
    "    return df\n",
    "\n",
    "# Fetch comparative responses\n",
    "comparative_df = fetch_comparative_responses(model_name=\"StanfordAIMI/CheXagent-8b\", limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display some examples\n",
    "if not comparative_df.empty:\n",
    "    # Extract perturbation type from question_category\n",
    "    comparative_df['perturbation_type'] = comparative_df['question_category'].apply(lambda x: x.replace('visual_perturb_', ''))\n",
    "    \n",
    "    # Group by perturbation type\n",
    "    perturbation_types = comparative_df['perturbation_type'].unique()\n",
    "    \n",
    "    for perturb_type in perturbation_types[:2]:  # Show examples for first two perturbation types\n",
    "        example = comparative_df[comparative_df['perturbation_type'] == perturb_type].iloc[0]\n",
    "        \n",
    "        print(f\"\\nExample for {perturb_type} perturbation:\")\n",
    "        print(f\"Question: {example['question']}\")\n",
    "        print(\"\\nOriginal image response:\")\n",
    "        print(example['original_answer'])\n",
    "        print(\"\\nPerturbed image response:\")\n",
    "        print(example['perturbed_answer'])\n",
    "        print(\"\\n\" + \"-\"*80)\n",
    "        \n",
    "        # Display the images side by side\n",
    "        visualize_perturbation(\n",
    "            original_path=example['original_image'],\n",
    "            perturbed_path=example['perturbed_image'],\n",
    "            perturbation_type=perturb_type,\n",
    "            ssim_value=perturbation_results[\n",
    "                (perturbation_results['perturbation_type'] == perturb_type) & \n",
    "                (perturbation_results['perturbed_image'] == example['perturbed_image'])\n",
    "            ]['ssim'].values[0] if not perturbation_results.empty else 0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate response similarity metrics\n",
    "if not comparative_df.empty:\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    \n",
    "    def calculate_similarity(text1, text2):\n",
    "        \"\"\"\n",
    "        Calculate cosine similarity between two texts.\n",
    "        \n",
    "        Args:\n",
    "            text1 (str): First text\n",
    "            text2 (str): Second text\n",
    "            \n",
    "        Returns:\n",
    "            float: Cosine similarity\n",
    "        \"\"\"\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
    "        return cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
    "    \n",
    "    # Calculate similarity for each pair\n",
    "    comparative_df['similarity'] = comparative_df.apply(\n",
    "        lambda row: calculate_similarity(row['original_answer'], row['perturbed_answer']),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Group by perturbation type and calculate average similarity\n",
    "    similarity_by_type = comparative_df.groupby('perturbation_type')['similarity'].agg(['mean', 'std', 'min', 'max'])\n",
    "    print(\"Response similarity by perturbation type:\")\n",
    "    print(similarity_by_type)\n",
    "    \n",
    "    # Visualize similarity by perturbation type\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    similarity_by_type['mean'].plot(kind='bar', yerr=similarity_by_type['std'], capsize=5)\n",
    "    plt.title('Response Similarity by Perturbation Type')\n",
    "    plt.xlabel('Perturbation Type')\n",
    "    plt.ylabel('Cosine Similarity')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Next Steps\n",
    "\n",
    "In this notebook, we've evaluated the CheXagent model's robustness to various visual perturbations.\n",
    "\n",
    "### Key Findings\n",
    "- Created perturbed versions of chest X-ray images using different perturbation methods\n",
    "- Evaluated CheXagent-8b performance on these perturbed images\n",
    "- Compared responses between original and perturbed images to measure impact\n",
    "- Identified perturbation types that most affect model performance\n",
    "\n",
    "### Perturbation Impact Analysis\n",
    "- Gaussian noise: [Brief summary of impact]\n",
    "- Checkerboard patterns: [Brief summary of impact]\n",
    "- Moir√© patterns: [Brief summary of impact]\n",
    "- Arrow artifacts: [Brief summary of impact]\n",
    "\n",
    "### Next Steps\n",
    "- Proceed to notebook `04_model_evaluation_gpt_baseline.ipynb` to evaluate GPT-4 Vision on the same dataset\n",
    "- Then continue with Claude and other models for comparison\n",
    "- Finally, use the VSF-Med framework for comprehensive vulnerability scoring across all models\n",
    "\n",
    "This analysis provides insights into the visual robustness of medical vision-language models and helps identify potential vulnerabilities that could affect clinical applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}