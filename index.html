<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VSF-Med: A Vulnerability Scoring Framework for Medical Vision-Language Models</title>
    <style>
        :root {
            --primary: #2c3e50;
            --secondary: #3498db;
            --accent: #e74c3c;
            --light: #ecf0f1;
            --dark: #34495e;
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f8f9fa;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }
        
        header {
            background-color: var(--primary);
            color: white;
            padding: 60px 0 40px;
            text-align: center;
        }
        
        header h1 {
            font-size: 2.5rem;
            margin-bottom: 15px;
        }
        
        header p {
            font-size: 1.2rem;
            max-width: 800px;
            margin: 0 auto;
        }
        
        nav {
            background-color: var(--dark);
            position: sticky;
            top: 0;
            z-index: 100;
        }
        
        .nav-links {
            display: flex;
            list-style: none;
            justify-content: center;
            flex-wrap: wrap;
        }
        
        .nav-links li a {
            display: block;
            color: white;
            text-decoration: none;
            padding: 15px 20px;
            transition: background-color 0.3s;
        }
        
        .nav-links li a:hover {
            background-color: var(--secondary);
        }
        
        section {
            padding: 60px 0;
        }
        
        section:nth-child(odd) {
            background-color: white;
        }
        
        h2 {
            font-size: 2rem;
            margin-bottom: 30px;
            color: var(--primary);
            text-align: center;
        }
        
        h3 {
            font-size: 1.5rem;
            margin: 25px 0 15px;
            color: var(--dark);
        }
        
        p {
            margin-bottom: 20px;
        }
        
        .btn {
            display: inline-block;
            background-color: var(--secondary);
            color: white;
            padding: 12px 24px;
            text-decoration: none;
            border-radius: 4px;
            transition: background-color 0.3s;
            font-weight: bold;
            margin: 10px 0;
        }
        
        .btn:hover {
            background-color: #2980b9;
        }
        
        .grid {
            display: flex;
            flex-direction: column;
            gap: 30px;
            margin: 40px 0;
        }
        
        @media (min-width: 768px) {
            .grid {
                flex-direction: row;
                flex-wrap: wrap;
            }
            
            .grid .card {
                flex: 1;
                min-width: 45%;
            }
        }
        
        .card {
            background-color: white;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            transition: transform 0.3s, box-shadow 0.3s;
            display: block;
            width: 100%;
        }
        
        .card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.1);
        }
        
        .card-header {
            background-color: #34495e;
            color: white;
            padding: 20px;
        }
        
        .card-header h3 {
            color: white;
            margin: 0;
        }
        
        .card-body {
            padding: 20px;
        }
        
        .card-body ul {
            padding-left: 20px;
        }
        
        pre {
            background-color: #f1f1f1;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            margin: 20px 0;
        }
        
        code {
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9rem;
        }
        
        ul, ol {
            padding-left: 20px;
            margin-bottom: 20px;
        }
        
        li {
            margin-bottom: 8px;
        }
        
        footer {
            background-color: var(--primary);
            color: white;
            text-align: center;
            padding: 30px 0;
        }
        
        .github-link {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 10px;
            margin: 20px 0;
        }
        
        @media (max-width: 768px) {
            header {
                padding: 40px 0 30px;
            }
            
            header h1 {
                font-size: 2rem;
            }
            
            section {
                padding: 40px 0;
            }
            
            .nav-links li a {
                padding: 10px 15px;
            }
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1>VSF-Med</h1>
            <p>A Vulnerability Scoring Framework for Medical Vision-Language Models</p>
        </div>
    </header>
    
    <nav>
        <ul class="nav-links">
            <li><a href="#overview">Overview</a></li>
            <li><a href="#structure">Structure</a></li>
            <li><a href="#workflow">Workflow</a></li>
            <li><a href="#attack-categories">Attack Categories</a></li>
            <li><a href="#notebooks">Notebooks</a></li>
            <li><a href="#installation">Installation</a></li>
            <li><a href="#usage">Usage</a></li>
        </ul>
    </nav>
    
    <main>
        <section id="overview">
            <div class="container">
                <h2>Overview</h2>
                <p>VSF-Med is a comprehensive framework designed to systematically evaluate the safety, reliability, and adversarial robustness of Vision-Language Models (Vision LLMs) in clinical imaging applications.</p>
                
                <h3>Vulnerability Dimensions</h3>
                <div class="grid">
                    <div class="card">
                        <div class="card-header">
                            <h3>Safety Dimensions</h3>
                        </div>
                        <div class="card-body">
                            <ul>
                                <li>Prompt injection effectiveness</li>
                                <li>Jailbreak resilience</li>
                                <li>Potential confidentiality breach</li>
                                <li>Risk of misinformation</li>
                            </ul>
                        </div>
                    </div>
                    <div class="card">
                        <div class="card-header">
                            <h3>Reliability Dimensions</h3>
                        </div>
                        <div class="card-body">
                            <ul>
                                <li>Denial of service resilience</li>
                                <li>Persistence of attack effects</li>
                                <li>Safety bypass success</li>
                                <li>Impact on medical decision support</li>
                            </ul>
                        </div>
                    </div>
                </div>
                
                <p>We apply this framework to ten clinically motivated adversarial scenarios, ranging from contextual prompt injections to image perturbations, using the MIMIC-CXR dataset.</p>
            </div>
        </section>
        
        <section id="structure">
            <div class="container">
                <h2>Repository Structure</h2>
                <pre><code>VSF-Med/
├── src/                         # Source code
│   ├── config/                  # Configuration files
│   │   └── default_config.yaml  # Default configuration
│   ├── database/                # Database schemas
│   │   └── dbschema.sql         # PostgreSQL database schema
│   ├── models/                  # Model implementations
│   │   └── evaluation/          # Evaluation models
│   │       └── vulnerability_scoring.py  # VSF-Med scoring framework
│   └── utils/                   # Utility functions
│       ├── database/            # Database utilities
│       │   └── database_utils.py  # Database operations
│       ├── perturbations/       # Perturbation utilities
│       │   ├── image_perturbations.py  # Visual perturbation methods
│       │   └── text_perturbations.py   # Text attack methods
│       └── visualization/       # Visualization utilities
│           └── image_utils.py   # Image analysis tools
├── notebooks/                   # Main experiment notebooks
│   ├── 01_data_preparation_adversarial_samples.ipynb   # Data preparation
│   ├── 02_model_evaluation_chexagent_baseline.ipynb    # CheXagent baseline
│   ├── 03_model_evaluation_chexagent_perturbed.ipynb   # CheXagent perturbation tests
│   ├── 04_model_evaluation_gpt_baseline.ipynb          # GPT-4o baseline
│   ├── 05_vulnerability_scoring_framework.ipynb        # Applying VSF-Med
│   ├── 06_model_evaluation_claude.ipynb                # Claude model tests
│   ├── 07_benchmarking_models.ipynb                    # Model comparison
│   └── 08_analysis_radiologist_comparison.ipynb        # Radiologist comparison
├── templates/                   # Templates for experiments
│   ├── text_attack_templates.txt          # Text attack patterns
│   ├── visual_perturbation_methods.txt    # Visual attack methods
│   └── vsf_scoring_rubric.txt             # Scoring rubric</code></pre>
            </div>
        </section>
        
        <section id="workflow">
            <div class="container">
                <h2>Evaluation Workflow</h2>
                <ol>
                    <li><strong>Data Preparation:</strong> Prepare a diverse selection of 5,000 frontal chest X-ray studies from MIMIC-CXR, stratified by patient demographics and key pathologies.</li>
                    <li><strong>Adversarial Variant Generation:</strong>
                        <ul>
                            <li>Text attacks: 18 attack categories with 2-4 expert-curated prompt templates each</li>
                            <li>Visual attacks: 6 perturbation methods (Gaussian noise, checkerboard, random arrow overlay, Moiré pattern, steganographic hide, LSB extraction)</li>
                        </ul>
                    </li>
                    <li><strong>Model Evaluation:</strong> Test multiple vision-language models on both standard and adversarial inputs:
                        <ul>
                            <li>CheXagent-8b: Specialized medical imaging model</li>
                            <li>GPT-4o: General-purpose multimodal model</li>
                            <li>Claude: General-purpose multimodal model</li>
                        </ul>
                    </li>
                    <li><strong>Vulnerability Scoring:</strong> Apply the VSF-Med framework to score model outputs across vulnerability dimensions.</li>
                    <li><strong>Benchmarking:</strong> Compare performance across models to identify strengths and weaknesses.</li>
                    <li><strong>Clinical Comparison:</strong> Compare model outputs with radiologist interpretations to assess clinical impact.</li>
                </ol>
            </div>
        </section>
        
        <section id="attack-categories">
            <div class="container">
                <h2>Attack Categories</h2>
                <div class="grid">
                    <div class="card">
                        <div class="card-header">
                            <h3>Text Attack Categories</h3>
                        </div>
                        <div class="card-body">
                            <p>Our framework formalizes 18 different attack categories including:</p>
                            <ul>
                                <li>Prompt Injection</li>
                                <li>Jailbreak Attempts</li>
                                <li>Confidentiality Breach</li>
                                <li>Misinformation Generation</li>
                                <li>Denial-of-Service</li>
                                <li>Persistence Attacks</li>
                                <li>Safety Bypass</li>
                                <li>Semantic Shift</li>
                                <li>Omission Attacks</li>
                                <li>Over-Confidence Induction</li>
                            </ul>
                        </div>
                    </div>
                    <div class="card">
                        <div class="card-header">
                            <h3>Visual Perturbation Methods</h3>
                        </div>
                        <div class="card-body">
                            <p>We apply six visual perturbation techniques to test model robustness:</p>
                            <ul>
                                <li>Gaussian noise at various levels</li>
                                <li>Checkerboard overlays (single or tiled)</li>
                                <li>Moiré patterns with adjustable frequency</li>
                                <li>Random arrow artifacts</li>
                                <li>Steganographic information hiding</li>
                                <li>LSB-plane extraction</li>
                            </ul>
                            <p>Perturbation parameters are optimized via grid search to balance imperceptibility (SSIM ≥ 0.85) with attack potency.</p>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        
        <section id="notebooks">
            <div class="container">
                <h2>Jupyter Notebooks</h2>
                <p>The experimental workflow is organized in sequential Jupyter notebooks:</p>
                
                <div class="grid">
                    <div class="card">
                        <div class="card-header">
                            <h3>Data Preparation & Sample Generation</h3>
                        </div>
                        <div class="card-body">
                            <ul>
                                <li><strong>01_data_preparation_adversarial_samples.ipynb</strong>: Prepares datasets and generates adversarial samples using 18 attack categories and 6 perturbation methods.</li>
                            </ul>
                        </div>
                    </div>
                    
                    <div class="card">
                        <div class="card-header">
                            <h3>Model Evaluation Notebooks</h3>
                        </div>
                        <div class="card-body">
                            <ul>
                                <li><strong>02_model_evaluation_chexagent_baseline.ipynb</strong>: Evaluates the baseline performance of StanfordAIMI's CheXagent-8b model on unperturbed images.</li>
                                <li><strong>03_model_evaluation_chexagent_perturbed.ipynb</strong>: Tests CheXagent against visually perturbed images to assess robustness.</li>
                                <li><strong>04_model_evaluation_gpt_baseline.ipynb</strong>: Evaluates the baseline performance of GPT-4o Vision on standard inputs.</li>
                                <li><strong>06_model_evaluation_claude.ipynb</strong>: Tests Anthropic's Claude model on both standard and adversarial inputs.</li>
                            </ul>
                        </div>
                    </div>
                    
                    <div class="card">
                        <div class="card-header">
                            <h3>Analysis Notebooks</h3>
                        </div>
                        <div class="card-body">
                            <ul>
                                <li><strong>05_vulnerability_scoring_framework.ipynb</strong>: Applies the VSF-Med framework to score model responses across 8 vulnerability dimensions.</li>
                                <li><strong>07_benchmarking_models.ipynb</strong>: Performs comprehensive cross-model comparison and benchmark analysis.</li>
                                <li><strong>08_analysis_radiologist_comparison.ipynb</strong>: Compares model performance with radiologist ground truth to assess clinical impact.</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        
        <section id="installation">
            <div class="container">
                <h2>Installation</h2>
                <pre><code># Clone the repository
git clone https://github.com/UNHSAILLab/VSF-Med.git
cd VSF-Med

# Create and activate virtual environment (optional but recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt</code></pre>
                
                <h3>Requirements</h3>
                <ul>
                    <li>Python 3.8+</li>
                    <li>API keys:
                        <ul>
                            <li>OpenAI API key (for GPT-4o access)</li>
                            <li>Anthropic API key (for Claude access)</li>
                        </ul>
                    </li>
                    <li>MIMIC-CXR dataset access</li>
                    <li>PostgreSQL database</li>
                    <li>Required Python libraries:
                        <ul>
                            <li>pandas, numpy</li>
                            <li>sqlalchemy, psycopg2-binary</li>
                            <li>openai, anthropic</li>
                            <li>PIL, cv2, matplotlib, scikit-image</li>
                            <li>seaborn, plotly, nltk</li>
                        </ul>
                    </li>
                </ul>
            </div>
        </section>
        
        <section id="usage">
            <div class="container">
                <h2>Usage</h2>
                
                <h3>Configuration</h3>
                <ol>
                    <li>Copy and customize the default configuration:
                        <pre><code>cp src/config/default_config.yaml src/config/my_config.yaml</code></pre>
                    </li>
                    <li>Edit <code>my_config.yaml</code> to set database credentials, API keys, and data paths.</li>
                </ol>
                
                <h3>Running Experiments</h3>
                <p>The experimental workflow is organized in sequential notebooks:</p>
                
                <pre><code># 1. Data Preparation and Adversarial Sample Generation
jupyter notebook notebooks/01_data_preparation_adversarial_samples.ipynb

# 2. Model Baseline Evaluations
jupyter notebook notebooks/02_model_evaluation_chexagent_baseline.ipynb
jupyter notebook notebooks/04_model_evaluation_gpt_baseline.ipynb
jupyter notebook notebooks/06_model_evaluation_claude.ipynb

# 3. Adversarial Testing
jupyter notebook notebooks/03_model_evaluation_chexagent_perturbed.ipynb

# 4. Vulnerability Scoring and Analysis
jupyter notebook notebooks/05_vulnerability_scoring_framework.ipynb
jupyter notebook notebooks/07_benchmarking_models.ipynb
jupyter notebook notebooks/08_analysis_radiologist_comparison.ipynb</code></pre>
                
                <h3>Citation</h3>
                <pre><code>@article{vsf-med2024,
  title={VSF-Med: A Vulnerability Scoring Framework for Medical Vision-Language Models},
  author={[Author names]},
  journal={[Journal]},
  year={2024}
}</code></pre>
            </div>
        </section>
    </main>
    
    <footer>
        <div class="container">
            <p>This project is licensed under the terms of the included LICENSE file.</p>
            <div class="github-link">
                <a href="https://github.com/UNHSAILLab/VSF-Med" class="btn" target="_blank">View on GitHub</a>
            </div>
            <p>&copy; 2024 UNH SAIL Lab</p>
        </div>
    </footer>
</body>
</html>